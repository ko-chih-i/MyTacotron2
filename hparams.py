import numpy as np
import tensorflow as tf
class HParams(dict):
    def __getattr__(self, name):
        return self[name]

    def __setattr__(self, name, value):
        self[name] = value

    # 修改 __getstate__ 方法
    def __getstate__(self):
        # 返回普通字典，避免返回 dict_items
        return dict(self)

    def __setstate__(self, state):
        # 恢復狀態為普通字典
        self.update(state)

hparams = HParams({
    # General hyperparameters
    "cleaners": "english_cleaners",
    "tacotron_num_gpus": 1,
    "wavenet_num_gpus": 1,
    "split_on_cpu": True,

    # Audio
    "num_mels": 80,
    "num_freq": 1025,
    "rescale": True,
    "rescaling_max": 0.999,
    "clip_mels_length": True,
    "max_mel_frames": 900,
    "use_lws": False,
    "silence_threshold": 2,
    "n_fft": 2048,
    "hop_size": 275,
    "win_size": 1100,
    "sample_rate": 22050,
    "frame_shift_ms": None,
    "magnitude_power": 2.0,
    "trim_silence": True,
    "trim_fft_size": 2048,
    "trim_hop_size": 512,
    "trim_top_db": 40,
    "signal_normalization": True,
    "allow_clipping_in_normalization": True,
    "symmetric_mels": True,
    "max_abs_value": 4.0,
    "normalize_for_wavenet": True,
    "clip_for_wavenet": True,
    "wavenet_pad_sides": 1,
    "preemphasize": True,
    "preemphasis": 0.97,
    "min_level_db": -100,
    "ref_level_db": 20,
    "fmin": 55,
    "fmax": 7600,
    "power": 1.5,
    "griffin_lim_iters": 60,
    "GL_on_GPU": True,

    # Tacotron
    "outputs_per_step": 1,
    "stop_at_any": True,
    "batch_norm_position": "after",
    "clip_outputs": True,
    "lower_bound_decay": 0.1,
    "embedding_dim": 512,
    "enc_conv_num_layers": 3,
    "enc_conv_kernel_size": (5,),
    "enc_conv_channels": 512,
    "encoder_lstm_units": 256,
    "smoothing": False,
    "attention_dim": 128,
    "attention_filters": 32,
    "attention_kernel": (31,),
    "cumulative_weights": True,
    "synthesis_constraint": False,
    "synthesis_constraint_type": "window",
    "attention_win_size": 7,
    "prenet_layers": [256, 256],
    "decoder_layers": 2,
    "decoder_lstm_units": 1024,
    "max_iters": 10000,
    "postnet_num_layers": 5,
    "postnet_kernel_size": (5,),
    "postnet_channels": 512,
    "cbhg_kernels": 8,
    "cbhg_conv_channels": 128,
    "cbhg_pool_size": 2,
    "cbhg_projection": 256,
    "cbhg_projection_kernel_size": 3,
    "cbhg_highwaynet_layers": 4,
    "cbhg_highway_units": 128,
    "cbhg_rnn_units": 128,
    "mask_encoder": True,
    "mask_decoder": False,
    "cross_entropy_pos_weight": 1,
    "predict_linear": True,

    # Wavenet
    "input_type": "raw",
    "quantize_channels": 2 ** 16,
    "use_bias": True,
    "legacy": True,
    "residual_legacy": True,
    "log_scale_min": float(np.log(1e-14)),
    "log_scale_min_gauss": float(np.log(1e-7)),
    "cdf_loss": False,
    "out_channels": 2,
    "layers": 20,
    "stacks": 2,
    "residual_channels": 128,
    "gate_channels": 256,
    "skip_out_channels": 128,
    "kernel_size": 3,
    "cin_channels": 80,
    "upsample_type": "SubPixel",
    "upsample_activation": "Relu",
    "upsample_scales": [11, 25],
    "freq_axis_kernel_size": 3,
    "leaky_alpha": 0.4,
    "NN_init": True,
    "NN_scaler": 0.3,
    "gin_channels": -1,
    "use_speaker_embedding": True,
    "n_speakers": 5,
    "speakers_path": None,
    "speakers": ["speaker0", "speaker1", "speaker2", "speaker3", "speaker4"],

    # Tacotron Training
    "tacotron_random_seed": 5339,
    "tacotron_data_random_state": 1234,
    "tacotron_swap_with_cpu": False,
    "tacotron_batch_size": 32,
    "tacotron_train_steps": 32,  # 我家的

    "tacotron_synthesis_batch_size": 1,
    "tacotron_test_size": 0.05,
    "tacotron_test_batches": None,
    "tacotron_decay_learning_rate": True,
    "tacotron_start_decay": 40000,
    "tacotron_decay_steps": 18000,
    "tacotron_decay_rate": 0.5,
    "tacotron_initial_learning_rate": 1e-3,
    "tacotron_final_learning_rate": 1e-4,
    "tacotron_adam_beta1": 0.9,
    "tacotron_adam_beta2": 0.999,
    "tacotron_adam_epsilon": 1e-6,
    "tacotron_reg_weight": 1e-6,
    "tacotron_scale_regularization": False,
    "tacotron_zoneout_rate": 0.1,
    "tacotron_dropout_rate": 0.5,
    "tacotron_clip_gradients": True,
    "tacotron_natural_eval": False,
    "tacotron_teacher_forcing_mode": "constant",
    "tacotron_teacher_forcing_ratio": 1.0,
    "tacotron_teacher_forcing_init_ratio": 1.0,
    "tacotron_teacher_forcing_final_ratio": 0.0,
    "tacotron_teacher_forcing_start_decay": 10000,
    "tacotron_teacher_forcing_decay_steps": 40000,
    "tacotron_teacher_forcing_decay_alpha": None,
    "tacotron_fine_tuning": False,
    "checkpoint_interval": 1000,  # 我家的
    "summary_interval": 100,  # 每100步將訓練資訊寫入到 TensorBoard
    "eval_interval": 1000,


    # Wavenet Training
    "wavenet_random_seed": 5339,
    "wavenet_data_random_state": 1234,
    "wavenet_swap_with_cpu": False,
    "wavenet_batch_size": 8,
    "wavenet_synthesis_batch_size": 20,
    "wavenet_test_size": None,
    "wavenet_test_batches": 1,
    "wavenet_lr_schedule": "exponential",
    "wavenet_learning_rate": 1e-3,
    "wavenet_warmup": float(4000),
    "wavenet_decay_rate": 0.5,
    "wavenet_decay_steps": 200000,
    "wavenet_adam_beta1": 0.9,
    "wavenet_adam_beta2": 0.999,
    "wavenet_adam_epsilon": 1e-6,
    "wavenet_clip_gradients": True,
    "wavenet_ema_decay": 0.9999,
    "wavenet_weight_normalization": False,
    "wavenet_init_scale": 1.0,
    "wavenet_dropout": 0.05,
    "wavenet_gradient_max_norm": 100.0,
    "wavenet_gradient_max_value": 5.0,
    "max_time_sec": None,
    "max_time_steps": 11000,
    "wavenet_natural_eval": False,
    "train_with_GTA": True,

    # Eval/Debug
    "sentences": [
        "Scientists at the CERN laboratory say they have discovered a new particle.",
        "There's a way to measure the acute emotional intelligence that has never gone out of style.",
        "President Trump met with other leaders at the Group of 20 conference.",
    ],
    "wavenet_synth_debug": False,
    "wavenet_debug_wavs": ["training_data/audio/audio-LJ001-0008.npy"],
    "wavenet_debug_mels": ["training_data/mels/mel-LJ001-0008.npy"],
})
